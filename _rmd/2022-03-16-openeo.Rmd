---
title: "Processing large scale satellite imagery with openEO Platform and R"
author: "Edzer Pebesma, Florian Lahn, Matthias Mohr, Peter Zellner"
date:  "Nov 17, 2022"
comments: false
layout: post
categories: r
---


TOC

[DOWNLOADHERE]

**Summary**:
[openEO](https://openeo.org) is an open source, community-based
API for cloud-based processing of Earth Observation data. This blog
introduces the R openeo client, and demonstrates a sample analysis
using the [openEO Platform](https://openeo.cloud) for processing.

```{r}
if (file.exists("con.RData"))
		load("con.RData")
library(openeo)
active_connection(con)
```

```{r eval=!exists("con")}
library(openeo)
con = openeo::connect("https://openeo.cloud")
```
```{r eval=FALSE}
login()
```
```{r}
# list_collections()
collection = "SENTINEL2_L2A"
coll_meta = describe_collection(collection)
```

```{r echo=FALSE}
save(list = "con", file = "con.RData")
```

```{r}
library(sf)
bbox = st_bbox(c(xmin = 7, xmax = 7.01, ymin = 52, ymax = 52.01), crs = 'EPSG:4326')
bbox = list(west = bbox[[1]],
            east = bbox[[3]],
            south = bbox[[2]],
            north = bbox[[4]])
bands = c("B04", "B08")
time_range = list("2018-01-01", "2019-01-01")
p = openeo::processes()
```

```{r}
ndvi = function(data, context) {
  red = data[1]
  nir = data[2]
  (nir-red)/(nir+red)
}
data = p$load_collection(id = collection, 
                         spatial_extent = bbox,
                         temporal_extent = time_range, 
                         bands = bands) 
calc_ndvi = p$reduce_dimension(data = data,
                               dimension = "bands",
                               reducer = ndvi)
```

```{r}
intervals = list(c('2018-01-01', '2018-02-01'),
                 c('2018-02-01', '2018-03-01'),
                 c('2018-03-01', '2018-04-01'),
                 c('2018-04-01', '2018-05-01'),
                 c('2018-05-01', '2018-06-01'), 
                 c('2018-06-01', '2018-07-01'), 
                 c('2018-07-01', '2018-08-01'),
                 c('2018-08-01', '2018-09-01'),
                 c('2018-09-01', '2018-10-01'), 
                 c('2018-10-01', '2018-11-01'),
                 c('2018-11-01', '2018-12-01'), 
                 c('2018-12-01', '2018-12-30'))
# and labels
labels = sapply(intervals, head, 1) # create labels from list

# add the process node
temp_period = p$aggregate_temporal(data = calc_ndvi,
                                   intervals = intervals,
                                   reducer = function(data, context){p$median(data)},
                                   labels = labels,
                                   dimension = "t")
result = p$save_result(data = temp_period, format="NetCDF")
```

```{r}
# synchronous:
compute_result(result, format = "NetCDF", output_file = "ndvi.nc", con = con)
```

```{r eval=FALSE}
# asynchronous:
job = create_job(graph = result,
                 title = "ndvi.nc",
                 description = "ndvi.nc",
                 format = "netCDF")

start_job(job = job$id) # use the id of the job (job$id) to start the job
job_list = list_jobs() # here you can see your jobs and their status

result_obj = list_results(job = job$id)
result_obj

status(job) # wait until it says finished, then:
```

```{r eval=FALSE}
dwnld = download_results(job = job$id, 
                         folder = "./") # adjust path here
```

Show locally:
```{r}
library(stars)
r = read_stars("ndvi.nc")
plot(r)
library(mapview)
mapview(r)
```
